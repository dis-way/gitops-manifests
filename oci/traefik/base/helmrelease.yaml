apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: traefik-crds
  namespace: traefik
spec:
  chart:
    spec:
      chart: traefik-crds
      reconcileStrategy: ChartVersion
      sourceRef:
        kind: HelmRepository
        name: traefik
        namespace: traefik
      # renovate: datasource=helm registryUrl=https://traefik.github.io/charts packageName=traefik-crds
      version: 1.13.1
  interval: 1h
  timeout: 5m
  install:
    remediation:
      retries: 5
  upgrade:
    remediation:
      retries: 5
  values: {}
---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: altinn-traefik
  namespace: traefik
spec:
  chart:
    spec:
      chart: traefik
      reconcileStrategy: ChartVersion
      sourceRef:
        kind: HelmRepository
        name: traefik
        namespace: traefik
      # renovate: datasource=helm registryUrl=https://traefik.github.io/charts packageName=traefik
      version: 38.0.2
  interval: 1h
  timeout: 5m
  dependsOn:
    - name: traefik-crds
      namespace: traefik
  install:
    crds: Skip
    remediation:
      retries: 5
  upgrade:
    crds: Skip
    remediation:
      retries: 5
  values:
    image:
      registry: altinncr.azurecr.io
    deployment:
      replicas: 3
      labels:
        release: traefik
      podAnnotations:
        linkerd.io/inject: enabled
        config.linkerd.io/skip-inbound-ports: 8000,8443,9100
        config.linkerd.io/proxy-cpu-request: 50m
        config.linkerd.io/proxy-memory-limit: 250Mi
        config.linkerd.io/proxy-memory-request: 40Mi
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    podDisruptionBudget:
      enabled: true
      minAvailable: 1
    ingressClass:
      enabled: false
    providers:
      kubernetesCRD:
        enabled: true
      kubernetesIngress:
        enabled: false
      kubernetesGateway:
        enabled: false
    global:
      checkNewVersion: false
      sendAnonymousUsage: false
    ports:
      # Default Traefik ports (web:80, websecure:443) are disabled in favor of custom ports
      # This allows for custom port configuration with specific networking requirements
      web: null
      websecure: null
      # Custom HTTP port configuration (maps internal 8000 to external 80)
      http:
        port: 8000
        expose:
          default: true
        exposedPort: 80
        protocol: TCP
        redirections:
          entryPoint:
            to: https
            scheme: https
            permanent: true
        forwardedHeaders:
          insecure: false
          trustedIPs:
            - "${AKS_SYSP00L_IP_PREFIX_0}"
            - "${AKS_SYSP00L_IP_PREFIX_1}"
            - "${AKS_WORKPOOL_IP_PREFIX_0}"
            - "${AKS_WORKPOOL_IP_PREFIX_1}"
      # Custom HTTPS port configuration (maps internal 8443 to external 443)
      # This separation allows for better container security and port management
      # Benefits: 1) Avoids running as root (ports >1024), 2) Linkerd compatibility,
      # 3) Clear separation between internal/external port mapping
      https:
        port: 8443
        expose:
          default: true
        exposedPort: 443
        protocol: TCP
        forwardedHeaders:
          insecure: false
          trustedIPs:
            - "${AKS_SYSP00L_IP_PREFIX_0}"
            - "${AKS_SYSP00L_IP_PREFIX_1}"
            - "${AKS_WORKPOOL_IP_PREFIX_0}"
            - "${AKS_WORKPOOL_IP_PREFIX_1}"
        tls:
          enabled: true
          options: ""
          certResolver: ""
          domains: []
    tlsOptions:
      default:
        minVersion: VersionTLS12
        cipherSuites:
          - TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256
          - TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384
          - TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
          - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
          - TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
    tlsStore:
      default:
        defaultCertificate:
          secretName: ssl-cert
    service:
      annotations:
        service.beta.kubernetes.io/azure-load-balancer-resource-group: "${AKS_NODE_RG}"
        service.beta.kubernetes.io/azure-load-balancer-ipv4: "${PUBLIC_IP_V4}"
        service.beta.kubernetes.io/azure-load-balancer-ipv6: "${PUBLIC_IP_V6}"
      spec:
        externalTrafficPolicy: "${EXTERNAL_TRAFFIC_POLICY:=Local}"
      ipFamilyPolicy: PreferDualStack
      ipFamilies:
        - IPv4
        - IPv6
    resources:
      requests:
        cpu: "100m"
        memory: "100Mi"
    experimental:
      otlpLogs: true
    metrics:
      prometheus: null
      otlp:
        enabled: true
        grpc:
          enabled: true
          endpoint: "${OTEL_ENDPOINT:=otel-collector.monitoring.svc.cluster.local:4317}"
          insecure: true
    tracing:
      otlp:
        enabled: true
        grpc:
          enabled: true
          endpoint: "${OTEL_ENDPOINT:=otel-collector.monitoring.svc.cluster.local:4317}"
          insecure: true
    logs:
      general:
        level: "ERROR"
        otlp:
          enabled: true
          grpc:
            enabled: true
            endpoint: "${OTEL_ENDPOINT:=otel-collector.monitoring.svc.cluster.local:4317}"
            insecure: true
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: app.kubernetes.io/name
                    operator: In
                    values:
                      - traefik
              topologyKey: kubernetes.io/hostname
    extraObjects: []
